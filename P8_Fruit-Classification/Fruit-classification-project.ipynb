{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fruit-Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tIiIl2hEWqlq"
      },
      "source": [
        "## Setup and configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xz7oY3YcPSZe"
      },
      "source": [
        "1. Firstly, we'll import usefull packages.\n",
        "2. Then, we'll load the data, before visualize and preprocess it.\n",
        "3. We'll try a simple CNN model and then we will evaluate its performances.\n",
        "4. And finally, we'll use techniques such as data augmentation, learning rate decay and dropout to increase our model's accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C4VkgMMepiyf"
      },
      "source": [
        "**Import Packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wx9m5esyW0qh",
        "colab": {}
      },
      "source": [
        "import numpy as np                          # linear algebra\n",
        "import os                                   # used for loading the data\n",
        "from sklearn.metrics import confusion_matrix# confusion matrix to carry out error analysis\n",
        "import seaborn as sn                        # heatmap\n",
        "from sklearn.utils import shuffle           # shuffle the data\n",
        "import matplotlib.pyplot as plt             # 2D plotting library\n",
        "import tensorflow as tf                     # best library ever"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRE_MsgEC6uT",
        "colab_type": "text"
      },
      "source": [
        "Kaggle API setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7ztDLtHDGJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir .kaggle\n",
        "\n",
        "import json\n",
        "token = {\"username\":\"npqbuu\",\"key\":\"224292a46181101043b9eaa22bc77a39\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4CBzRKrFpFP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "18fe56f1-2101-43e2-98c0-e14e48ea7e52"
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "- path is now set to: {/content}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEcZJ3JpDjmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download dataset from Kaggle\n",
        "\n",
        "!kaggle datasets download -d moltean/fruits -p /content\n",
        "!unzip \\*.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qpcquX3ptpJ1"
      },
      "source": [
        "**Import datas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-KhtOc8mPKv3",
        "colab": {}
      },
      "source": [
        "# Global varriables\n",
        "train_data_dir = 'fruits-360/Training'\n",
        "test_data_dir = 'fruits-360/Test'\n",
        "\n",
        "img_height = 100\n",
        "img_width = 100\n",
        "batch_size = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kwF_f6aCWNv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d05f44a-4aef-47fe-da9b-bbf6308c3ca7"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "#Load dataset\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    subset='training') # set as training data\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir, # same directory as training data\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    subset='validation') # set as validation data\n",
        "\n",
        "test_generator = train_datagen.flow_from_directory(\n",
        "    test_data_dir, # same directory as training data\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical') # set as test data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 45852 images belonging to 114 classes.\n",
            "Found 11424 images belonging to 114 classes.\n",
            "Found 19548 images belonging to 114 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0ac9aVoCWNz",
        "colab_type": "text"
      },
      "source": [
        "**Let's explore the dataset**\n",
        "\n",
        "We can, for example, ask ourselves:\n",
        "\n",
        "- How many training and testing examples do we have ?\n",
        "- What is the size of the images ?\n",
        "- What is the proportion of each observed category ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsfUibqMCWN0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d957a719-fa74-4753-fffb-2ee64dcb6846"
      },
      "source": [
        "train_generator.image_shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 100, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-RG1SjvCWN3",
        "colab_type": "text"
      },
      "source": [
        "## Model evaluation\n",
        "Steps are:\n",
        "1. Build the model\n",
        "2. Compile the model\n",
        "3. Train / fit the data to the model\n",
        "4. Evaluate the model on the testing set\n",
        "5. Carry out an error analysis of our model.\n",
        "\n",
        "We can build an easy model composed of different layers such as:\n",
        "- Conv2D: (32 filters of size 3 by 3) The features will be \"extracted\" from the image.\n",
        "- MaxPooling2D: The images get half sized.\n",
        "- Flatten: Transforms the format of the images from a 2d-array to a 1d-array of 100 100 3 pixel values.\n",
        "- Relu : given a value x, returns max(x, 0).\n",
        "- Softmax: 6 neurons, probability that the image belongs to one of the classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_MyRXfECWN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (100, 100, 3)), # the nn will learn the good filter to use\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxiYekB_CWN6",
        "colab_type": "text"
      },
      "source": [
        "Then, we can compile it with some parameters such as:\n",
        "- Optimizer: adam = RMSProp + Momentum. What is Momentum and RMSProp ?\n",
        "- Momentum = takes into account past gradient to have a better update.\n",
        "- RMSProp = exponentially weighted average of the squares of past gradients.\n",
        "- Loss function: we use sparse categorical crossentropy for classification, each images belongs to one class only"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HUrK2XDCWN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGgtqob8CWN9",
        "colab_type": "text"
      },
      "source": [
        "We fit the model to the data from the training set. The neural network will learn by itself the pattern in order to distinguish each category."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyDaEMQVCWN9",
        "colab_type": "text"
      },
      "source": [
        "Fitting/Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcHlPT9yCWN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
        "STEP_SIZE_VALID = validation_generator.n //validation_generator.batch_size\n",
        "\n",
        "model.fit_generator(generator = train_generator,\n",
        "                    steps_per_epoch = STEP_SIZE_TRAIN,\n",
        "                    validation_data = validation_generator,\n",
        "                    validation_steps = STEP_SIZE_VALID,\n",
        "                    epochs = 10\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOv0K2yzCWOA",
        "colab_type": "text"
      },
      "source": [
        "Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbQAnYgZCWOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('my_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6nGfbDSCWOD",
        "colab_type": "text"
      },
      "source": [
        "Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVm5IuCvCWOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('my_model.h5') # Load model\n",
        "\n",
        "model.evaluate_generator(generator=validation_generator, steps=STEP_SIZE_VALID)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCto7wCGCWOH",
        "colab_type": "text"
      },
      "source": [
        "Predict the output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApFtcRVzCWOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
        "test_generator.reset()\n",
        "pred=model.predict_generator(test_generator,\n",
        "steps=STEP_SIZE_TEST,\n",
        "verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}